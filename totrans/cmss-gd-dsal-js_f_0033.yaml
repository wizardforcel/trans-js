- en: The Soul of `Big O`
  id: totrans-0
  prefs:
  - PREF_H2
  stylish: true
  type: TYPE_NORMAL
  zh: '`Big O`的灵魂'
- en: 'Now that we’ve encountered `O(N)` and `O(1)`，we begin to see that `Big O` notation
    does more than simply describe the number of steps an algorithm takes, such as
    with a hard number like `22` or `400`。Rather, it’s an answer to that key question
    on your forehead: if there are `N` data elements, how many steps will the algorithm
    take?'
  id: totrans-1
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 现在我们遇到了`O(N)`和`O(1)`，开始看到`Big O`记号不仅仅描述算法所需的步骤数量，比如`22`或`400`这样具体的数字。相反，它回答了你脑海中那个关键的问题：如果有`N`个数据元素，算法将需要多少步骤？
- en: While that key question is indeed the strict definition of `Big O`，there’s actually
    more to `Big O` than meets the eye.
  id: totrans-2
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 虽然那个关键问题确实是`Big O`的严格定义，但实际上`Big O`比表面看到的要复杂得多。
- en: Let’s say we have an algorithm that always takes three steps no matter how much
    data there is. That is, for `N` elements, the algorithm always takes three steps.
    How would you express that in terms of `Big O`?
  id: totrans-3
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 假设我们有一个算法，无论数据量多少，它总是需要三步。也就是说，对于`N`个元素，该算法总是需要三步。你会如何用`Big O`来表示呢？
- en: Based on everything you’ve learned up to this point, you’d probably say that
    it’s `O(3)`。
  id: totrans-4
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 根据你到目前为止所学的内容，你可能会说它是`O(3)`。
- en: However, it’s actually `O(1)`。And that’s because of the next layer of understanding
    `Big O`，which I will reveal now.
  id: totrans-5
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 然而，它实际上是`O(1)`。这正是我现在将揭示的理解`Big O`的下一层次。
- en: While `Big O` is an expression of the number of an algorithm’s steps relative
    to `N` data elements, that alone misses the deeper why behind `Big O`，what I dub
    the “soul of `Big O`。”
  id: totrans-6
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 虽然`Big O`是算法步骤相对于`N`个数据元素的表达，但单靠这一点无法揭示`Big O`背后的更深层原因，我称之为“`Big O`的灵魂”。
- en: 'The soul of `Big O` is what `Big O` is truly concerned about: how will an algorithm’s
    performance change as the data increases?'
  id: totrans-7
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: '`Big O`的灵魂就是它真正关心的：随着数据的增加，算法的性能将如何变化？'
- en: This is the soul of `Big O`. `Big O` doesn’t want to simply tell you how many
    steps an algorithm takes. It wants to tell you the story of how the number of
    steps increases as the data changes.
  id: totrans-8
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 这就是`Big O`的灵魂。`Big O`并不只是想告诉你一个算法需要多少步骤。它想要讲述的是当数据变化时，步骤数量如何增加的故事。
- en: Viewed with this lens, we don’t care very much whether an algorithm is `O(1)`
    or `O(3)`。Because both algorithms are the type that aren’t affected by increased
    data, as their number of steps remains constant, they’re essentially the same
    kind of algorithm. They’re both algorithms whose steps remain constant irrespective
    of the data, and we don’t care to make a distinction between the two.
  id: totrans-9
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 从这个角度看，我们并不太关心一个算法是`O(1)`还是`O(3)`。因为这两种算法都不受数据增加的影响，步骤数量保持不变，它们本质上是同一种算法。它们都是步骤数量与数据无关的算法，我们不在乎区分这两者。
- en: An algorithm that is `O(N)`，on the other hand, is a different type of algorithm.
    It’s an algorithm whose performance is affected as we increase the data. More
    specifically, it’s the kind of algorithm whose steps increase in direct proportion
    to the data as the data increases. This is the story `O(N)` tells. It tells you
    about the proportional relationship between the data and the algorithm’s efficiency.
    It describes exactly how the number of steps increases as the data increases.
  id: totrans-10
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 另一方面，一个`O(N)`的算法是一种不同类型的算法。它的性能会随着数据的增加而受到影响。更具体地说，这种算法的步骤与数据成正比地增加。这就是`O(N)`所讲述的故事。它告诉你数据与算法效率之间的比例关系。它确切描述了随着数据增加，步骤数量如何增加。
- en: 'Look at how these two types of algorithms are plotted on a graph:'
  id: totrans-11
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 看看这两种算法在图表上的绘制方式：
- en: '![images/big_o_notation/graph_1.png](images/big_o_notation/graph_1.png)'
  id: totrans-12
  prefs: []
  stylish: true
  type: TYPE_IMG
  zh: '![images/big_o_notation/graph_1.png](images/big_o_notation/graph_1.png)'
- en: Notice that `O(N)` makes a perfect diagonal line. This is because for every
    additional piece of data, the algorithm takes one additional step. Accordingly,
    the more data, the more steps the algorithm will take.
  id: totrans-13
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 注意到`O(N)`形成了一条完美的对角线。这是因为每增加一条数据，算法就需要额外增加一步。因此，数据越多，算法所需的步骤也越多。
- en: Contrast this with `O(1)`，which is a perfect horizontal line. No matter how
    much data there is, the number of steps remains constant.
  id: totrans-14
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 与此相比，`O(1)`是一条完美的水平线。无论数据量多大，步骤的数量始终保持不变。
- en: Deeper into the Soul of `Big O`
  id: totrans-15
  prefs:
  - PREF_H3
  stylish: true
  type: TYPE_NORMAL
  zh: 深入探讨`Big O`的灵魂
- en: To see why the soul of `Big O` is so important, let’s go one level deeper. Say
    we had an algorithm of constant time that always took 100 steps no matter how
    much data there was. Would you consider that to be more or less performant than
    an algorithm that is `O(N)`?
  id: totrans-16
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 为了理解`Big O`的核心为何如此重要，让我们深入探讨一下。假设我们有一个恒定时间的算法，无论数据量有多少，它始终需要100步。你认为这比`O(N)`算法更高效还是更低效？
- en: 'Take a look at the following graph:'
  id: totrans-17
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 请看以下图表：
- en: '![images/big_o_notation/graph_2.png](images/big_o_notation/graph_2.png)'
  id: totrans-18
  prefs: []
  stylish: true
  type: TYPE_IMG
  zh: '![images/big_o_notation/graph_2.png](images/big_o_notation/graph_2.png)'
- en: 'As the graph depicts, for a data set that is fewer than 100 elements, an `O(N)`
    algorithm takes fewer steps than the `O(1)` 100-step algorithm. At exactly 100
    elements, the lines cross, meaning the two algorithms take the same number of
    steps, namely 100。But here’s the key point: for all arrays greater than 100, the
    `O(N)` algorithm takes more steps.'
  id: totrans-19
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 正如图表所示，对于少于100个元素的数据集，`O(N)`算法的步骤少于`O(1)`的100步算法。在正好100个元素时，两条线交叉，这意味着两个算法所需的步骤相同，即100步。但关键点是：对于所有超过100的数组，`O(N)`算法所需的步骤更多。
- en: Because there will always be some amount of data at which the tides turn, and
    `O(N)` takes more steps from that point until infinity, `O(N)` is considered to
    be, on the whole, less efficient than `O(1)` no matter how many steps the `O(1)`
    algorithm actually takes.
  id: totrans-20
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 因为总会有某个数据量使得局势逆转，从那时起`O(N)`的步骤将比`O(1)`更多，因此不管`O(1)`算法实际需要多少步，`O(N)`被认为整体上低效于`O(1)`。
- en: The same is true even for an `O(1)` algorithm that always takes one million
    steps. As the data increases, there will inevitably reach a point at which `O(N)`
    becomes less efficient than the `O(1)` algorithm and will remain so up toward
    an infinite amount of data.
  id: totrans-21
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 对于一个始终需要一百万步的`O(1)`算法，情况也是如此。随着数据量的增加，必然会达到一个点，此时`O(N)`比`O(1)`算法效率更低，并且在数据量趋于无穷时依然如此。
- en: Same Algorithm, Different Scenarios
  id: totrans-22
  prefs:
  - PREF_H3
  stylish: true
  type: TYPE_NORMAL
  zh: 同一算法，不同场景
- en: As you learned in the previous chapters, linear search isn’t always `O(N)`.
    It’s true that if the item we’re looking for is in the final cell of the array,
    it will take `N` steps to find it. But when the item we’re searching for is found
    in the first cell of the array, linear search will find the item in just one step.
    So this case of linear search would be described as `O(1)`. If we were to describe
    the efficiency of linear search in its totality, we’d say that linear search is
    `O(1)` in a best-case scenario and `O(N)` in a worst-case scenario.
  id: totrans-23
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 正如你在前面的章节中所学，线性搜索并不总是`O(N)`。确实，如果我们要寻找的项目在数组的最后一个单元格，它将需要`N`步才能找到。但是当我们要寻找的项目在数组的第一个单元格时，线性搜索只需一步即可找到。因此，这种情况下的线性搜索可以被描述为`O(1)`。如果我们要描述线性搜索的整体效率，我们可以说在最佳情况下线性搜索是`O(1)`，而在最坏情况下是`O(N)`。
- en: While `Big O` effectively describes both the best- and worst-case scenarios
    of a given algorithm, `Big O` notation generally refers to the worst-case scenario
    unless specified otherwise. This is why most references will describe linear search
    as being `O(N)` even though it can be `O(1)` in a best-case scenario.
  id: totrans-24
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 虽然`Big O`有效地描述了给定算法的最佳和最坏情况，但`Big O`符号通常指的是最坏情况，除非另有说明。这就是为什么大多数参考资料将线性搜索描述为`O(N)`，即使在最佳情况下它可以是`O(1)`。
- en: 'This is because a “pessimistic” approach can be a useful tool: knowing exactly
    how inefficient an algorithm can get in a worst-case scenario prepares us for
    the worst and may have a strong impact on our choices.'
  id: totrans-25
  prefs: []
  stylish: true
  type: TYPE_NORMAL
  zh: 这是因为“悲观”的方法可以成为一个有用的工具：确切知道在最坏情况下一个算法会有多低效，可以让我们为最坏情况做好准备，并可能对我们的选择产生重大影响。

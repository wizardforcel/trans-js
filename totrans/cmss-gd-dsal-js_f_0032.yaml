- en: 'Big O: How Many Steps Relative to N Elements?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Big O achieves consistency by focusing on the number of steps an algorithm takes,
    but in a specific way. Let’s start off by applying Big O to the algorithm of linear
    search.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a worst-case scenario, linear search will take as many steps as there are
    elements in the array. As we’ve previously phrased it: for N elements in the array,
    linear search can take up to N steps. The appropriate way to express this in Big
    O notation is:'
  prefs: []
  type: TYPE_NORMAL
- en: O(N)
  prefs: []
  type: TYPE_NORMAL
- en: Some pronounce this as “Big Oh of N.” Others call it “Order of N.” My personal
    preference, however, is “Oh of N.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what the notation means. It expresses the answer to what we’ll call
    the key question. The key question is this: if there are N data elements, how
    many steps will the algorithm take? Go ahead and read that sentence again. Then,
    emblazon it on your forehead, as this is the definition of Big O notation that
    we’ll be using throughout the rest of this book.'
  prefs: []
  type: TYPE_NORMAL
- en: The answer to the key question lies within the parentheses of our Big O expression.
    O(N) says that the answer to the key question is that the algorithm will take
    N steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s quickly review the thought process for expressing time complexity with
    Big O notation, again using the example of linear search. First we ask the key
    question: if there are N data elements in an array, how many steps will linear
    search take? Because the answer to this question is that linear search will take
    N steps, we express this as O(N). For the record, an algorithm that is O(N) is
    also known as having linear time.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s contrast this with how Big O would express the efficiency of reading
    from a standard array. As you learned in Chapter 1, [​*Why Data Structures Matter*​](f_0013.xhtml#chp.understanding_data_structures),
    reading from an array takes just one step, no matter how large the array is. To
    figure out how to express this in Big O terms, we’re going to again ask the key
    question: if there are N data elements, how many steps will reading from an array
    take? The answer is that reading takes just one step. So we express this as O(1),
    which I pronounce “Oh of 1.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'O(1) is interesting since although our key question revolves around N (“If
    there are N data elements, how many steps will the algorithm take?”), the answer
    has nothing to do with N. And that’s actually the whole point: no matter how many
    elements an array has, reading from the array always takes one step.'
  prefs: []
  type: TYPE_NORMAL
- en: And this is why O(1) is considered the “fastest” kind of algorithm. Even as
    the data increases, an O(1) algorithm doesn’t take any additional steps. The algorithm
    always takes a constant number of steps no matter what N is. In fact, an O(1)
    algorithm can also be referred to as having constant time.
  prefs: []
  type: TYPE_NORMAL
- en: So, Where's the Math?
  prefs: []
  type: TYPE_NORMAL
- en: 'As I mentioned earlier in this book, I’m taking an easy-to-understand approach
    to the topic of Big O. That’s not the only way to do it; if you were to take a
    traditional college course on algorithms, you’d probably be introduced to Big
    O from a mathematical perspective. Big O is originally a concept from mathematics,
    and therefore, it’s often described in mathematical terms. For example, one way
    of describing Big O is that it describes the upper bound of the growth rate of
    a function, or that if a function g(x) grows no faster than a function f(x), then
    g is said to be a member of O(f). Depending on your mathematics background, that
    either makes sense or doesn’t help very much. I’ve written this book so that you
    don’t need as much math to understand the concept. If you want to dig further
    into the math behind Big O, check out Introduction to Algorithms by Thomas H.
    Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein (MIT Press,
    2009) for a full mathematical explanation. Justin Abrahms also provides a pretty
    good definition in his article: [https://justin.abrah.ms/computer-science/understanding-big-o-formal-definition.html](https://justin.abrah.ms/computer-science/understanding-big-o-formal-definition.html).'
  prefs: []
  type: TYPE_NORMAL

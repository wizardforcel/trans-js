- en: Big O Categories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This leads us to the next concept within Big O: Big O notation only concerns
    itself with general categories of algorithm speeds.'
  prefs: []
  type: TYPE_NORMAL
- en: As an analogy, let’s talk about physical buildings. There are, of course, many
    different types of buildings. There are one-floor single-family homes, and two-floor
    single-family homes, and three-floor single-family homes. There are high-rise
    apartment buildings with varying numbers of floors. And there are skyscrapers
    with various heights and shapes.
  prefs: []
  type: TYPE_NORMAL
- en: If we were to compare two buildings, one of which is a single-family home and
    one of which is a skyscraper, it becomes almost moot to mention how many floors
    each one has. Because the two buildings are so incredibly different in their sizes
    and functions, we don’t need to say, “This one is a two-story home, while the
    other is a one-hundred-floor skyscraper.” We may as well just call one a house
    and the other a skyscraper. Calling them by their general categories is enough
    to signify their vast differences.
  prefs: []
  type: TYPE_NORMAL
- en: The same applies to algorithm efficiencies. If we compare, say, an O(N) algorithm
    with an O(N²) algorithm, the two efficiencies are so different that it doesn’t
    really matter whether the O(N) algorithm is actually O(2N), or O(N / 2) or even
    O(100N).
  prefs: []
  type: TYPE_NORMAL
- en: Now, here’s why O(N) and O(N²) are considered two separate categories, while
    O(N) and O(100N) are part of the same category.
  prefs: []
  type: TYPE_NORMAL
- en: Remember [​*The Soul of Big O*​](f_0033.xhtml#sect.soul-of-big-o). Big O notation
    doesn’t care merely about the number of steps an algorithm takes. It cares about
    the long-term trajectory of the algorithm’s steps as the data increases. O(N)
    tells a story of straight growth—that the steps increase in a straight line according
    to some proportion of the data. This is true even when the steps are 100N. O(N²)
    tells a different story—one of exponential growth.
  prefs: []
  type: TYPE_NORMAL
- en: Exponential growth is a completely different category compared to any form of
    O(N). This point is really driven home when we consider that O(N²) will, at some
    point in data growth, become slower than O(N) multiplied by any factor.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following graph, you can see how O(N²) becomes slower than various factors
    of N:'
  prefs: []
  type: TYPE_NORMAL
- en: '![images/optimizing_code_with_and_without_big_o/o_n_2_vs_o_n_graph.png](images/optimizing_code_with_and_without_big_o/o_n_2_vs_o_n_graph.png)'
  prefs: []
  type: TYPE_IMG
- en: Therefore, when comparing two efficiencies that belong to two different categories
    of Big O, it’s enough to identify them by their general category. Talking about
    O(2N) when compared to O(N²) is like talking about a two-story house compared
    to a skyscraper. We may as well just say that O(2N) is part of the general category
    of O(N).
  prefs: []
  type: TYPE_NORMAL
- en: All the types of Big O we’ve encountered, whether it’s O(1), O(log N), O(N),
    O(N²), or the types we’ll encounter later in this book, are general categories
    of Big O that are widely different from each other. Multiplying or dividing the
    number of steps by a regular number doesn’t make them change to another category.
  prefs: []
  type: TYPE_NORMAL
- en: However, when two algorithms fall under the same classification of Big O, it
    doesn’t necessarily mean that both algorithms have the same speed. After all,
    Bubble Sort is twice as slow as Selection Sort even though both are O(N²). So
    while Big O is perfect for contrasting algorithms that fall under different classifications
    of Big O, when two algorithms fall under the same classification, further analysis
    is required to determine which algorithm is faster.
  prefs: []
  type: TYPE_NORMAL
- en: A Practical Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s return to the first code example from Chapter 1, with minor changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ​  | ​**function**​ printNumbersVersionOne(upperLimit) { |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | ​**let**​ number = 2; |'
  prefs: []
  type: TYPE_TB
- en: '| ​  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | ​**while**​ (number <= upperLimit) { |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | ​**if**​ (number % 2 === 0) { |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | console.log(number); |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | } |'
  prefs: []
  type: TYPE_TB
- en: '| ​  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | number += 1; |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | } |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | } |'
  prefs: []
  type: TYPE_TB
- en: '| ​  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | ​**function**​ printNumbersVersionTwo(upperLimit) { |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | ​**let**​ number = 2; |'
  prefs: []
  type: TYPE_TB
- en: '| ​  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | ​**while**​ (number <= upperLimit) { |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | console.log(number); |'
  prefs: []
  type: TYPE_TB
- en: '| ​  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | number += 2; |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | } |'
  prefs: []
  type: TYPE_TB
- en: '| ​  | } |'
  prefs: []
  type: TYPE_TB
- en: Here we have two algorithms for accomplishing the same task, namely printing
    all even numbers starting from 2 to some upperLimit. (In Chapter 1, the upper
    limit was fixed at 100, while here we let the user pass in a number as the upperLimit.)
  prefs: []
  type: TYPE_NORMAL
- en: I noted in Chapter 1 that the first version takes twice as many steps as the
    second version, but now let’s see how this plays out in terms of Big O.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, Big O expresses the answer to the key question: if there are N data
    elements, how many steps will the algorithm take? In this case, though, N isn’t
    the size of an array, but simply the number we pass into the function to serve
    as the upperLimit.'
  prefs: []
  type: TYPE_NORMAL
- en: The first version takes about N steps. That is, if the upperLimit is 100, the
    function takes about 100 steps. (It really takes 99 steps since it starts the
    count at 2.) So we can safely say that the first algorithm has a time complexity
    of O(N).
  prefs: []
  type: TYPE_NORMAL
- en: The second version takes N / 2 steps. When the upperLimit is 100, the function
    takes just 50 steps. While it would be tempting to call this O(N / 2), you’ve
    now learned that we drop the constants and reduce the expression to O(N).
  prefs: []
  type: TYPE_NORMAL
- en: Now, the second version is twice as fast as the first one and would naturally
    be the better choice. This is another great example of where two algorithms can
    be expressed the same way using Big O notation but further analysis is needed
    to figure out which algorithm is faster.
  prefs: []
  type: TYPE_NORMAL
- en: Significant Steps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s apply one more level of analysis to the previous example. If we look again
    at the first version, printNumbersVersionOne, we said that it takes N steps. This
    is because the loop runs N times, with N being the upperLimit.
  prefs: []
  type: TYPE_NORMAL
- en: But does the function really take just N steps?
  prefs: []
  type: TYPE_NORMAL
- en: If we really break things down, we can see that multiple steps occur in each
    round of the loop.
  prefs: []
  type: TYPE_NORMAL
- en: First, we have the comparison step (if number % 2 == 0), which checks whether
    the number is divisible by 2\. This comparison happens in each round of the loop.
  prefs: []
  type: TYPE_NORMAL
- en: Second, we have the print step (console.log(number)), which happens just for
    the even numbers. This, then, occurs in every other round of the loop.
  prefs: []
  type: TYPE_NORMAL
- en: And third, we have number += 1, which runs in each round of the loop.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapters, I alluded to the fact that you’d learn how to determine
    which steps are significant enough to be counted when expressing the Big O of
    an algorithm. In our case, then, which of these steps are considered significant?
    Do we care about the comparisons, the printing, or the incrementing of number?
  prefs: []
  type: TYPE_NORMAL
- en: The answer is that all steps are significant. It’s just that when we express
    the steps in Big O terms, we drop the constants and thereby simplify the expression.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s apply this here. If we count all the steps, we have N comparisons, N incrementings,
    and N / 2 printings. This adds up to 2.5N steps. However, because we eliminate
    the constant of 2.5, we express this as O(N). So which step was significant? They
    all were, but by dropping the constant, we effectively focus more on the number
    of times the loop runs rather than the exact details of what happens within the
    loop.
  prefs: []
  type: TYPE_NORMAL
